\chapter{Introducción}
\label{chap:introducion}

\lettrine{E}{n} este capítulo se expone la motivación de este \acrlong{tfm}, sus objetivos y la estructura de la memoria.

\section{Motivación}
\label{sec:motivacion}
La computación de altas prestaciones (\acrshort{hpc}, o \acrlong{hpc}) y la \acrlong{ia} (\acrshort{ia}) son actualmente disciplinas en boca de todos. Esta última es sin duda la más atractiva para el público general por los espectaculares avances que está proporcionando en diversos ámbitos de aplicación. Modelos que realizan tareas como conducción autónoma o creación instantánea de verdaderas obras de arte, así como la traducción en tiempo real en múltiples idiomas, nos hacen ver que las redes neuronales están evolucionando a enorme velocidad, y con ello sus posibles aplicaciones presentes y futuras. Debido al fuerte desarrollo de sistemas con inteligencia artificial, y la irrupción de este tipo de modelos en el \textit{mainstream}, son cada vez más necesarias arquitecturas de altas prestaciones y eficiencia energética para optimizar el rendimiento de su procesamiento.

\section{Objetivos}
\label{sec:objetivos}
El objetivo principal de este trabajo es el análisis y posible mejora del rendimiento de la ejecución de modelos de inteligencia artificial en la fase de inferencia, así como de su consumo energético. En esta memoria se realiza una breve introducción a una de las arquitecturas de redes neuronales más simples y su implementación de bajo nivel. En base a esta se analiza el rendimiento de estas redes y se proponen mejoras, así como una Prueba de Concepto de las mismas. También se propone una implementación del producto de matrices para redes neuronales dispersas mediante una arquitectura punto a punto (\textit{point-to-point} o p2p), y se compara su rendimiento con una de las librerías de matrices dispersas más empleadas. Esta comparación de rendimiento, debido al tipo de código empleado y con el fin de obtener una métrica apropiada en la que incidir en el futuro, se ha realizado utilizando curvas de \textit{speedup} complementadas con modelos \textit{roofline}.

Para satisfacer los objetivos de este trabajo y así obtener una comprensión detallada del funcionamiento a bajo nivel de este tipo de redes, se analiza su implementación en TensorFlow a la par que se desarrollan otras implementaciones alternativas basadas en generación estática de código C con múltiples \textit{backends}. Estos códigos se pueden generar en tres versiones diferentes, dos de ellas basadas en llamadas a funciones de librería (\texttt{OpenBLAS} y \texttt{librsb}), y una versión \textit{ad hoc} denominada \textit{point-to-point}.

\section{Estructura}
\label{sec:estructura}
En esta memoria se tratan las redes neuronales desde un punto de vista matemático y de implementación, para posteriormente proponer mejoras de rendimiento y eficiencia energética en base al perfilado de las mismas. Comenzando por el Capítulo \ref{chap:conceptos_basicos}, se tratan los conceptos más básicos de las redes neuronales \textit{feed-forward}, se detalla su implementación a alto nivel, y se presentan los conceptos básicos necesarios para la comprensión del resto de la memoria. En el Capítulo \ref{chap:analisis_estado_arte} se describe el estado del arte y, en concreto, se tratan los múltiples usos reales de las redes neuronales con diferentes arquitecturas pasadas y presentes, siendo un ejemplo de estas últimas las \textit{\acrlong{gan}} y los \textit{transformers}, entre otras. En este mismo capítulo se analizan los perfilados conducidos en las principales fuentes bibliográficas, para poner el foco en el aumento exponencial del consumo de energía que conllevarán estas redes en el futuro próximo. Como una posible solución se propone el podado de redes, junto a una Prueba de Concepto que demuestre la viabilidad de esta aproximación.

El funcionamiento de esta Prueba de Concepto (\textit{\acrlong{poc}} o \acrshort{poc}) se detalla en el Capítulo \ref{chap:desarrollo_poc}, donde se muestran, con un esquema de desarrollo incremental, los objetivos y pasos que se han seguido durante la creación de esta \acrshort{poc}. Tras el desarrollo de la \acrshort{poc}, se miden los rendimientos y se lleva a cabo el perfilado de las tres diferentes implementaciones que se desarrollaron, comparando así redes densas basadas en \texttt{OpenBLAS} con redes dispersas basadas por un lado en \texttt{librsb}, así como con redes basadas en arquitectura \textit{point-to-point} sin el empleo de librerías externas.

Finalmente, el Capítulo \ref{chap:conclusiones} presenta las conclusiones extraídas de este proceso y las líneas futuras de investigación, así como las disciplinas empleadas y habilidades adquiridas durante la realización del \acrshort{tfm} en el marco del Máster en Computación de Altas Prestaciones.